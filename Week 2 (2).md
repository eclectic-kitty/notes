---
title: Week 2
created: 2024-09-11T17:26:41.734Z
modified: 2024-09-11T18:36:42.286Z
---

# Week 2

## Max Matthews
Computer music pioneer
Developed some of the first music synthesis software called MUSIC (I - IV)
Bicycle Built Two, song with v early speech synthesis, used in 2001 (film)

Max/MSP partly named after him

- Key Insights from paper:
	- No theoretical limitations for sound generation
	- Limited only by cost and psychoacoustic knowledge
	- Serious composers should engage
- Versatility
	- Computers can produce a wider range of sounds than any existing instrument
	- Can be programmed to simulate or create new sounds
- Digital sounds synthesis
	- Any perceivable sound can be generated by treating numbers as samples of sound pressure waves
	- Complex sounds can be created by controlling paraemters such as amplitude, frequency, and envelope
- real-time and stored sound processing
	- sounds can be pre-computed, sotred, and replayed at higher rates
- Can also be used in composition

- Digital representation of sound
	- Pressure changes, cibrations, propagated a medium
		- Can be air, a wall, a building, water, etc.
	- Transducers convert vibrations into electrical signals
		- Electrical sound signals are 1-1 representations of the 
		- Quality of speakers affects the directness of this conversion
			- Our brains can fill this in, to a certain extent
	- A digital representation encodes a signal in a series of numbers
		- Each nimber represents value of the pressure at a given instant
		- To generate a digital signal, the amplitude of the sound is sampled at regular intervals, and arranged in time this is **analog-to-digital conversion**
		- Sampling process records a limited number of values from an infinite set that makes up the analog signal
			- **sampling period** is the time interval between each sample
			- **sampling frequency** is the inverse of the period (aka **sampling rate**)
			- To reconstruct a given signal, the sampling rate must be greater than twice the maximum frequency in the signal
				- This maximum is called the **Nyquist frequency**
				- Typical uncompressed sampling rate is 44.100 khz
					- Frequencies above 20 khz may not be heard, but they can still be sensed**?**
			- **foldover** is a phenomenon where frequencies that exceed the Nyquist frequency are bounced back down
		- Signal is reconstructed by applying a *sample-and-hold* process to sustain the voltage
			- Signal now has a stepped shape, frequencies not present in original signal that must be filtered out
		- Quality of signal can also be affected by bit-depth applied to amplitude levels
			-**quantization**
			- Typical bit-depths are of 16 or 24 bits
- Sound on the internet
	- MP3 was the most searched term in 1999
	- Today, streaming is 
	- Perceptual coding has had major impact, nearly everyone using it in formats like MP3 or similar (OGG for ex. was a non-proprietary format similar to MP3)
	- Recorded sound, waveform sound
	- structured audio
		- Does not carry sound itself
		- Sounds generated dynamically at runtime
		- Ex. MIDI sequencers, MOD trackers
		- Series of instructions instead
			- timing
			- pitch
		MIDI
			- Technical standard (1983)
			- ALlows communication between electronic music instruments and computers
			- Developed by an association of music companies such as KORG, Yamaha, MOOG, etc.
	- RIFF
		- Container for audio
			- Contains either WAV or AIFF files
			- Also contains a header with file info
	- Compression
		- Lossy vs lossless
			- lossless, when uncompressed, is an exact replica of original
			- lossy will lose some data
		perceptual audio coding
			- lossy technique
		- MP#
			- PCM digitally reproduces the waveform as accurately ap
			- human perception is imperfect and biased
			- Some elements are more important to our brains
			- perceptual coding focuses quality on the elements that are more preceived
			- PCM is 1-1
		- Frequency masking
			- For physiological reasons, some sounds can mask others
		- Temporal masking
			- even if sounds are offset, they can still be masked
